{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from unidecode import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('jairbolsonaro.json', 'r', encoding='utf8') as json_file:\n",
    "#     wordsBolsano = json.load(json_file)\n",
    "with open('LulaOficial.json', 'r', encoding='utf8') as json_file:\n",
    "     wordsLula = json.load(json_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFBolsanaro = pd.DataFrame(data=wordsBolsano)\n",
    "DFLula = pd.DataFrame(data=wordsLula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nao      4219\n",
       "lula     3941\n",
       "eu       2197\n",
       "tem      1423\n",
       "eles     1265\n",
       "         ... \n",
       "seu       327\n",
       "ate       325\n",
       "tinha     319\n",
       "foto:     317\n",
       "essa      315\n",
       "Name: palavras, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DFLula['created_at']\n",
    "DFLula['full_text'].value_counts().iloc[:10]\n",
    "DFLula['palavras'] = DFLula['full_text'].apply(lambda x: x.split())\n",
    "DFLula['ano'] = DFLula['created_at'].apply(lambda x: str(x)[25:32])\n",
    "# DFLula.groupby('ano').count()\n",
    "# DFLula['palavras'].value_counts()\n",
    "# minha_palavra = list([DFLula['palavras'],DFLula['ano']])   \n",
    "minha_palavra = list(DFLula['palavras'])   \n",
    "novo_conjunto = []\n",
    "# for a in minha_palavra[0]:\n",
    "for a in minha_palavra:\n",
    "    nova_lista = [] \n",
    "    for b in a:\n",
    "       nova_lista.append(b.split(', '))\n",
    "    novo_conjunto.append(nova_lista)\n",
    "a = novo_conjunto\n",
    "saida = np.concatenate((a))\n",
    "# print(saida)\n",
    "novo_conjunto2 = []\n",
    "artigos = ['-','a','as','a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', \n",
    "           'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', \n",
    "           'v', 'w', 'x', 'y', 'z','p','c','q','das','aos','ao','e','i','o',\n",
    "           'os','pela','pelo','como','u','do','dos','de','se','por','da','em',\n",
    "           'que','na','no','para','com','um','uma','mais','ricardo','stu']\n",
    "for a in saida:\n",
    "    nova_lista2 = [] \n",
    "    for b in a:\n",
    "         b = unidecode(b)\n",
    "#          b = re.sub('[!]@#$ü§îü§•üë∫ü•Åüö¥‚Äçüö®üö©üö¥‚Äç‚ù§\\ \",|\\?|\\.|\\!|\\/|\\;|\\:]', '', b)\n",
    "         b = b.lower() \n",
    "         if b in artigos:       \n",
    "            b = re.sub('[!@#$ü§îü§•üë∫ü•Åüö¥‚Äçüö®üö©üö¥‚Äç‚ù§\\ |\\?|\\.|\\!|\\/|\\;|\\:]', '', b)\n",
    "         elif b and (not b.isspace()):\n",
    "            nova_lista2.append(remove_emoji(b))\n",
    "            novo_conjunto2.append(nova_lista2)\n",
    "a2 = novo_conjunto2\n",
    "saida2 = filter(None, a2)\n",
    "# saida2 = a2\n",
    "DFLula = pd.DataFrame(data=saida2)\n",
    "DFLula['palavras'] = DFLula[0]\n",
    "lista = list(DFLula['palavras'])\n",
    "# DFLula['palavras'].value_counts().iloc[:1000]\n",
    "# DFLula.sort_values(by='palavras')\n",
    "# DFLula.sort_values(by='palavras', ascending=False)\n",
    "# DFLula.groupby(0).value_counts()\n",
    "# DFLula.groupby(0).agg(pd.Series.mode)\n",
    "\n",
    "# DFLula.describe()\n",
    "# print(lista)\n",
    "DFLula['palavras'].value_counts().iloc[:70]\n",
    "# DFLula['ano'].value_counts() \n",
    "# DFLula['palavras'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
